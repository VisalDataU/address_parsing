{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visal/anaconda3/envs/keras/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Geo_Cambo_v2.csv', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['village_name'] = df['village_name'].str.replace('\\\"', \"\", regex=True)\n",
    "df['village_name'] = df['village_name'].str.replace('(', \"\", regex=True)\n",
    "df['village_name'] = df['village_name'].str.replace(')', \"\", regex=True)\n",
    "df['village_name'] = df['village_name'].str.replace('-', \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['com_id', 'com_com', 'dis_id', 'dis_name', 'pro_id', 'pro_name',\n",
       "       'village_id', 'village_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = list(pd.concat([df['pro_name'].drop_duplicates(), df['dis_name'].drop_duplicates(),\n",
    "                df['com_com'].drop_duplicates(), df['village_name'].drop_duplicates()]).drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs_df = pd.concat([df['pro_name'].drop_duplicates(), df['dis_name'].drop_duplicates(),\n",
    "                df['com_com'].drop_duplicates(), df['village_name'].drop_duplicates()]).to_frame(name='vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['com_id', 'dis_id', 'pro_id', 'village_id']:\n",
    "    df[col] = '0'+df[col] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = df[['pro_id', 'pro_name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_dict = dict(zip(df.pro_id, df.pro_name))\n",
    "dist_dict = dict(zip(df.dis_id, df.dis_name))\n",
    "com_dict = dict(zip(df.com_id, df.com_com))\n",
    "vill_dict = dict(zip(df.village_id, df.village_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {\n",
    "    'Province' : list(df.pro_name.drop_duplicates()),\n",
    "    'District' : list(df.dis_name.drop_duplicates()),\n",
    "    'Commune' : list(df.com_com.drop_duplicates()),\n",
    "    'Village' : list(df.village_name.drop_duplicates())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Kratie', 92)]\n"
     ]
    }
   ],
   "source": [
    "# iterating through list1 to extract \n",
    "# it's closest match from list2\n",
    "add = [\"Kraties\"]\n",
    "result = []\n",
    "for i in add:\n",
    "    f = []\n",
    "    pro = process.extract(i, pro_dict, limit=1, scorer=fuzz.ratio)[0][0]\n",
    "    dist = process.extract(i, dist_dict, limit=1, scorer=fuzz.ratio)[0][0]\n",
    "    com = process.extract(i, com_dict, limit=1, scorer=fuzz.ratio)[0][0]\n",
    "    vill = process.extract(i, vill_dict, limit=1, scorer=fuzz.ratio)[0][0]\n",
    "    f.append(pro)\n",
    "    f.append(dist)\n",
    "    f.append(com)\n",
    "    f.append(vill)\n",
    "    print(process.extract(i, f, limit=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Chhroy Basak' matches with 'Chrey Bak' in [Commune] with a score of: 76\n"
     ]
    }
   ],
   "source": [
    "confidenceLevels = pd.DataFrame({\n",
    "    'wordLength' : [1,2,3,4,5,6,7,8,9,10], \n",
    "    'minRatio' : [100,100,100,100,80,80,80,80,75,75]\n",
    "})\n",
    "\n",
    "def getFuzzyRatio(token = None, confidence_levels = True, default_level = 85):\n",
    "    \"\"\"\n",
    "    This function is meant to retrieve the matching minimum similarity ratio for a particular string length. \n",
    "    As string length decreases, you should work with higher ratios to ensure you are not matching words that shouldn't match.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check for appropriate formats\n",
    "    assert isinstance(token, str), \"Tokens can be str() type only\"\n",
    "    \n",
    "    # We check if confidence levels are set\n",
    "    if confidence_levels:\n",
    "        for i, row in confidenceLevels.iterrows():\n",
    "            if len(token) > confidenceLevels['wordLength'].max():\n",
    "                min_ratio = confidenceLevels['minRatio'].min()\n",
    "            else:\n",
    "                min_ratio = confidenceLevels.loc[confidenceLevels['wordLength'] == len(token)]['minRatio'].values[0]\n",
    "                \n",
    "    # Fallback if confidence levels are not set\n",
    "    else:\n",
    "        min_ratio = default_level\n",
    "        \n",
    "    return int(min_ratio)\n",
    "\n",
    "def getFuzzySimilarity(token = None, dictionary = None, min_ratio = None):\n",
    "    \"\"\"\n",
    "    This function uses the FuzzyWuzzy library to find the highest matching similary score of a token in a list of values.\n",
    "    We then compare the similary score of the fuzzy match with our minimum threshold and return a match if the match > treshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check for appropriate formats\n",
    "    assert isinstance(token, str), \"Tokens can be str() type only\"\n",
    "    assert isinstance(dictionary, dict), \"Dictionary format should be provided in the dictionary parameter.\"\n",
    "    assert isinstance(min_ratio, int), \"Integer format should be provided in the minimum-ratio parameter.\"\n",
    "    \n",
    "    for key, values in dictionary.items():\n",
    "        # Using the process option of FuzzyWuzzy, we can search through the entire dictionary for the best match\n",
    "        match = process.extractOne(token, values, scorer = fuzz.ratio)\n",
    "        # Match is a tuple with the match value and the similary score.\n",
    "        if min_ratio <= match[1]:\n",
    "            return (match + (key, ))  \n",
    "\n",
    "tokens = [\"Chhroy Basak\"]\n",
    "for token in tokens:\n",
    "    fuzzy_ratio = getFuzzyRatio(token = token, confidence_levels = True)\n",
    "    similarity_score = getFuzzySimilarity(token = token, dictionary = dictionary, min_ratio = fuzzy_ratio)\n",
    "    if not similarity_score == None:\n",
    "        print(\"'\" + token + \"'\" + \" matches with \" + \"'\"  + str(similarity_score[0]) + \"'\" + \" in [\" + similarity_score[2] + \"]\" + \" with a score of: \" + str(similarity_score[1]))              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siem Reap , Treang , Trea , Trea\n",
      "[('Trea', 100)]\n"
     ]
    }
   ],
   "source": [
    "address = 'Phum Trea Village, Stueng Mean Chey Commune, Meanchey District, Phnom Penh Province'\n",
    "address1 = 'Trea'\n",
    "for i in address1.split(','):\n",
    "    f = []\n",
    "    pro = process.extract(i, pro_dict, limit=1, scorer=fuzz.ratio)[0][0]\n",
    "    dist = process.extract(i, dist_dict, limit=1, scorer=fuzz.ratio)[0][0]\n",
    "    com = process.extract(i, com_dict, limit=1, scorer=fuzz.ratio)[0][0]\n",
    "    vill = process.extract(i, vill_dict, limit=1, scorer=fuzz.ratio)[0][0]\n",
    "    f.append(pro)\n",
    "    f.append(dist)\n",
    "    f.append(com)\n",
    "    f.append(vill)\n",
    "    print(pro, ',', dist, ',' , com,',' , vill)\n",
    "    print(process.extract(i, f, limit=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Trea', 100)]\n",
      "[('Stueng Mean chey 1', 95)]\n",
      "[('Mean Chey', 94)]\n",
      "[('Phnom Penh', 100)]\n"
     ]
    }
   ],
   "source": [
    "address = 'Trea, Stueng Mean Chey, Meanchey, Phnom Penh'\n",
    "address1 = 'Trea'\n",
    "for i in address.split(','):\n",
    "    f = []\n",
    "    pro = process.extract(i, pro_dict, limit=1, scorer=fuzz.ratio)[0][0]\n",
    "    dist = process.extract(i, dist_dict, limit=1, scorer=fuzz.ratio)[0][0]\n",
    "    com = process.extract(i, com_dict, limit=1, scorer=fuzz.ratio)[0][0]\n",
    "    vill = process.extract(i, vill_dict, limit=1, scorer=fuzz.ratio)[0][0]\n",
    "    f.append(pro)\n",
    "    f.append(dist)\n",
    "    f.append(com)\n",
    "    f.append(vill)\n",
    "    print(process.extract(i, f, limit=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mypy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff872530eef8e893d9aef85c9079af2769210a77098287e49de53e382973a372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
